{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5dcc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from numpy import nan\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from main_util_func import *\n",
    "from dataprep.clean import clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ccf7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "# map(functools.partial(add, y=2), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f297a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['LD_LIBRARY_PATH'] = \"/usr/local/cuda-10.1/lib64/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a722749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_parent_detect(filtered_researchers):\n",
    "    multi_parent = 0\n",
    "    multi_index= []\n",
    "    for i, row in filtered_researchers.iterrows():\n",
    "        edges = eval(row['input_edgelist'])\n",
    "        #print(type(edges))\n",
    "        #years = eval(row['input_node_years'])\n",
    "        graph = nx.DiGraph()\n",
    "        graph.add_edges_from(edges)\n",
    "        #node_year = dict(years)\n",
    "        #nx.set_node_attributes(graph, values = node_year, name='year')\n",
    "        #print(graph.nodes, graph.edges)\n",
    "        for node in graph.nodes:\n",
    "            #print(type(node))\n",
    "            parents = list(graph.predecessors(node))\n",
    "            if len(parents) > 1:\n",
    "                multi_parent +=1\n",
    "                multi_index.append(i)\n",
    "    return multi_parent, multi_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3956ea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    embeddings  = load_obj('combined_reduced_tsne_embed')\n",
    "\n",
    "    print(f\"embedding nodes : {len(embeddings)}\")\n",
    "    print(f\"embedding shape : {embeddings[1].shape}\")\n",
    "    embeddings[0] = np.array([0]*embeddings[1].shape[0])\n",
    "     \n",
    "    data_loc = './inter_files/path_model_with_tree_newer_rel_kept_input_output1.csv'  #\"older relation kept\"\n",
    "    #data_loc = './inter_files/path_model_input_output1.csv' #\"no relation removed (all relation kept)\"\n",
    "    data = pd.read_csv(data_loc, sep=',', lineterminator=\"\\n\", low_memory=False)\n",
    "    inferred_dtypes, cleaned_data = clean_df(data)\n",
    "    del data\n",
    "\n",
    "    cleaned_data['first_year']= cleaned_data['input_years_sequence'].apply(lambda x:eval(x)[1]) \n",
    "    #new after 05-05-2022\n",
    "    \n",
    "    cleaned_data['flag'] = cleaned_data['first_year']+15 <= 2021 #new\n",
    "    cleaned_data = cleaned_data[cleaned_data['flag']==True].copy() #new\n",
    "    cleaned_data['output_seq'] = cleaned_data['output_seq'].apply(lambda x : eval(x))\n",
    "    cleaned_data['paths'] = cleaned_data['paths'].apply(lambda x : eval(x))\n",
    "\n",
    "    num_paths = [len(paths) for paths in cleaned_data['paths'].values]\n",
    "    max_num_paths = max(num_paths)\n",
    "    print(f\"Max no. paths : {max_num_paths}\")\n",
    "    path_length = [len(path) for paths in cleaned_data['paths'].values for path in paths]\n",
    "    max_path_len = max(path_length)\n",
    "    print(f\"Max path len : {max_path_len}\")\n",
    "    padded_input_paths = []\n",
    "    for index, row in tqdm(cleaned_data.iterrows(), total=cleaned_data.shape[0]):\n",
    "        padded_path = pad_sequence(row['paths'], num_seq=max_num_paths, seq_length=max_path_len)\n",
    "        padded_input_paths.append(padded_path) \n",
    "    cleaned_data['padded_paths'] = padded_input_paths\n",
    "    #print(cleaned_data.columns)\n",
    "    multi_parent, multi_index = multi_parent_detect(cleaned_data)\n",
    "    print(f\"Family having researcher with multi parents: {multi_parent}\")\n",
    "    #print(multi_index)\n",
    "    \n",
    "    test_data = cleaned_data.loc[multi_index].copy()\n",
    "    print(test_data.shape)\n",
    "    del cleaned_data\n",
    "\n",
    "#     train_input = np.array([np.array(list1) for list1 in train_data['padded_paths'].values])\n",
    "#     train_output = np.array([np.array(list1) for list1 in train_data['output_seq'].values])\n",
    "    test_input = np.array([np.array(list1) for list1 in test_data['padded_paths'].values])\n",
    "    test_output = np.array([np.array(list1) for list1 in test_data['output_seq'].values])\n",
    "\n",
    "    \n",
    "    return embeddings, test_input, test_output, max_path_len, max_num_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221951a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(sequences,embeddings,max_num_paths,max_path_len):\n",
    "#     global embeddings\n",
    "#     global max_num_paths\n",
    "#     global max_path_len\n",
    "    seq = np.array([embeddings[int(node)] for seq in sequences for node in seq])\n",
    "    return seq.reshape(max_num_paths, max_path_len, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11424a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model3(model_file, enc_file, dec_file):\n",
    "    model     = load_model(model_file, compile=False)\n",
    "    model_enc = load_model(enc_file, compile=False)\n",
    "    model_dec = load_model(dec_file, compile=False)\n",
    "    return (model, model_enc, model_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759664fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(encoder_model, decoder_model, input_seq, input_length, output_size, max_num_seq, max_seq_len, embedding_size):\n",
    "    input_seq = input_seq.reshape(-1, max_num_seq, max_seq_len, embedding_size)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.array(input_length).reshape(-1, 1, output_size) #(N * 1 * 1)\n",
    "    #print(target_seq.shape)\n",
    "    decoded_seq = []\n",
    "\n",
    "    stop_condition = False\n",
    "    count = 0\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        #print(output_tokens)\n",
    "        decoded_seq.append(output_tokens)\n",
    "        #print(output_tokens.shape)\n",
    "        count+=1\n",
    "        #print(count)\n",
    "        if count >= max_seq_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = output_tokens\n",
    "        states_value = [h, c]\n",
    "    decoded_seq = np.hstack((decoded_seq))\n",
    "    return decoded_seq.reshape(-1, max_seq_len, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef47f6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With relation removed (older relation kept):\n",
      "embedding nodes : 268653\n",
      "embedding shape : (400,)\n",
      "Data Type Detection Report:\n",
      "\tThese data types are supported by DataPrep to clean: ['country']\n",
      "Column Headers Cleaning Report:\n",
      "No Headers Cleaned.\n",
      "Downcast Memory Report:\n",
      "\tMemory reducted from 81052290 to 79681494. New size: (98.31%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 824/43164 [00:00<00:05, 8239.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max no. paths : 52\n",
      "Max path len : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43164/43164 [00:04<00:00, 9121.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Family having researcher with multi parents: 1128\n",
      "(1128, 18)\n",
      "test input shape: (1128, 52, 5, 400)\n",
      "test output shape: (1128, 6)\n",
      "Error with relation removed-> Mean:1.1992622955833, Std:0.9352781169416587\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #print(f\"Without relation removed(all relation kept):\")\n",
    "    print(f\"With relation removed (older relation kept):\")\n",
    "    embeddings, test_input, test_output, max_path_len, max_num_paths = data_load()\n",
    "    mapping_other = functools.partial(mapping, embeddings=embeddings,max_num_paths=max_num_paths,max_path_len=max_path_len)\n",
    "    test_input =  np.array(list(map(mapping_other, test_input)))\n",
    "    print(f\"test input shape: {test_input.shape}\")\n",
    "    test_output = np.log2(test_output)\n",
    "    print(f\"test output shape: {test_output.shape}\")\n",
    "    max_num_seq = test_input.shape[1]\n",
    "    max_seq_len = test_input.shape[2]\n",
    "    embedding_size = test_input.shape[3]\n",
    "    output_size = 1\n",
    "\n",
    "    test_data = test_input\n",
    "    test_input_length = test_output[:,0]\n",
    "    test_actual_op = test_output[:,1:].reshape(-1,5,1)\n",
    "    error_list = []\n",
    "\n",
    "    years = [\"1950_1980_1980_1985\",\"1950_1985_1985_1990\", \"1950_1990_1990_1995\",\"1950_1995_1995_2000\",\"1950_1980_1995_2000\"]\n",
    "    #path_dec_32_512_0.0001_25_1950_1980_1995_2000_0.04324817657470703_0.1624655984963131_True_0.01\n",
    "    dataset = {}\n",
    "    for year in years:\n",
    "        temp=[]\n",
    "        model_file   = glob(f\"./exp_models/path_32_512_0.0001_25_{year}*True_0.01_nrk\")\n",
    "        encoder_file = glob(f\"./exp_models/path_enc_32_512_0.0001_25_{year}*True_0.01_nrk\")\n",
    "        decoder_file = glob(f\"./exp_models/path_dec_32_512_0.0001_25_{year}*True_0.01_nrk\")\n",
    "#         model_file   = glob(f\"./exp_models/path_32_512_0.0001_25_{year}*True_0.01\") #With relation kept\n",
    "#         encoder_file = glob(f\"./exp_models/path_enc_32_512_0.0001_25_{year}*True_0.01\")\n",
    "#         decoder_file = glob(f\"./exp_models/path_dec_32_512_0.0001_25_{year}*True_0.01\")\n",
    "        for file_inx in range(6):\n",
    "            model, encoder_model, decoder_model = load_model3(model_file[file_inx], encoder_file[file_inx], decoder_file[file_inx])\n",
    "            test_predicted_op = decode_sequence(encoder_model, decoder_model, test_data, test_input_length, output_size, max_num_seq, max_seq_len, embedding_size)\n",
    "            error = mse(test_predicted_op.reshape(-1,), test_actual_op.reshape(-1,))\n",
    "            error_list.append(error)\n",
    "            temp.append(error)\n",
    "        dataset[str(year)]=(np.mean(temp), np.std(temp))\n",
    "    avg_error =  np.mean(error_list)\n",
    "    std = np.std(error_list)\n",
    "    print(f\"Error with relation removed-> Mean:{avg_error}, Std:{std}\")\n",
    "    #print(f\"Error without relation removed-> Mean:{avg_error}, Std:{std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf06dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predicted_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b509ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_actual_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224f1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#glob(f\"./exp_models/path_dec_32_32_0.0001_25_{year}*True_0.01_oldrk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993986e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1950_1980_1980_1985': (11.84475482220445, 5.904536041657321),\n",
       " '1950_1985_1985_1990': (12.007767090805586, 3.5552801344161105),\n",
       " '1950_1990_1990_1995': (3.4040206701080944, 3.6804298760042427),\n",
       " '1950_1995_1995_2000': (4.018599642239562, 3.853051603010467),\n",
       " '1950_1980_1995_2000': (10.863088815688778, 7.6704058316229995)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ab52ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1950_1980_1980_1985': (1.5562725812366895, 1.0259584432534765),\n",
       " '1950_1985_1985_1990': (1.3307620452563567, 0.8018707570009993),\n",
       " '1950_1990_1990_1995': (0.5570353752792092, 0.4909129718384233),\n",
       " '1950_1995_1995_2000': (1.1258617373619033, 1.0288783745320078),\n",
       " '1950_1980_1995_2000': (1.4263797387823416, 0.8742872331746663)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77707c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  with relation removed\n",
    "# {'1950_1980_1980_1985': (1.314820141018356, 0.8301380089761211),\n",
    "#  '1950_1985_1985_1990': (0.838448149452543, 0.8131235937916369),\n",
    "#  '1950_1990_1990_1995': (0.5734713805111756, 0.28322045831154463),\n",
    "#  '1950_1995_1995_2000': (0.8145801653747169, 0.9274146325576711),\n",
    "#  '1950_1980_1995_2000': (1.1505943449076284, 1.0636817965990732)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without relation removed (results)\n",
    "\n",
    "# {'1950_1980_1980_1985': (1.9235642143992513, 0.7415566749356955),\n",
    "#  '1950_1985_1985_1990': (0.8826815717419967, 0.8292638474599289),\n",
    "#  '1950_1990_1990_1995': (1.3671353133720894, 1.4374834860291181),\n",
    "#  '1950_1995_1995_2000': (1.9457733611593966, 1.4761518765433876),\n",
    "#  '1950_1980_1995_2000': (1.9256257579640799, 1.3454863929371412)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb8634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error without relation removed-> Mean:1.6089553557902456, Std:1.2804592642682693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error with relation removed-> Mean:0.9385267230940997, Std:0.8685251846360821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb68534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8d56cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_actual_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b1639e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_predicted_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8bce1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, encoder_model, decoder_model = load_model3(model_file[file_inx], encoder_file[file_inx], decoder_file[file_inx])\n",
    "            \n",
    "#predicted_op = decode_sequence(enc, dec, encoder_input, decoder_input, max_seq_len=5)\n",
    "#predicted_op_1 = predicted_op.reshape(predicted_op.shape[0], predicted_op.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a15880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_m2 = np.sum(np.square(test_predicted_op-test_actual_op))/(test_predicted_op.shape[0]*test_predicted_op.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d42c795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[]+[1,2,3]+[4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2255118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
